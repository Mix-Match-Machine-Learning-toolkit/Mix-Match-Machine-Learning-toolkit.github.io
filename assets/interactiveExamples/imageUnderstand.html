<div id="Classifier">
    <div class="interactiveExampleIntro">
        <h3 class="exampleHeader">Visual question and answering</h3>
        <p>The capability understanding is most often used in the context of language. Here it is used to describe how ML
            can answer a question posed in human language about an image. For this it uses similar methods as with 'image categorize'
            to recognize what is visible in the images.
        </p>
        <p><span class='bold'>Model: </span> <a
            href="https://huggingface.co/dandelin/vilt-b32-finetuned-vqa" target="_blank"
            rel="noreferrer noopener">Vision-and-Language Transformer (ViLT)</a>
        <br>
        <span class='bold'>Data: </span><a href="https://visualqa.org/" target="_blank"
        rel="noreferrer noopener">VQA</a>
        <br>
        <span class='bold'>Example from: </span> <a
        href="https://huggingface.co/spaces/nielsr/comparing-VQA-models" target="_blank"
        rel="noreferrer noopener">Niels Rogge on Huggingface</a>
        
    </p>
    
        <div class="gradioDiv">

            <iframe src="https://nielsr-comparing-vqa-models.hf.space" frameborder="0" ></iframe>

            <!-- <a href="https://huggingface.co/spaces/johngoad/Image-Caption" target="_blank" rel="noreferrer noopener"></a> -->
        </div>
    </div>
</div>
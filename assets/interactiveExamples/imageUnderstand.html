<div id="Classifier">
    <div width="100%">
        <h3 class="exampleHeader">Visual question and answering</h3>
        <p>The capability understanding is most often used in the context of language. Here it is used to describe how ML
            can answer a question posed in human language about an image. For this it uses similar methods as with 'image categorize'
            to recognize what is visible in the images.
        </p>
        <p><span class='bold'>Model: </span> <a
            href="https://huggingface.co/dandelin/vilt-b32-finetuned-vqa" _blank"
            rel="noreferrer noopener">Vision-and-Language Transformer (ViLT)</a>
        <br>
        <span class='bold'>Data: </span><a href="https://visualqa.org/" target="_blank"
        rel="noreferrer noopener">VQA</a>
        <br>
        <span class="smallWarning">
            <i class="fa-solid fa-triangle-exclamation fa-lg" style="color: #1E475E;">&#160;
            </i> <i> Please be aware that these applications have not been checked for compliance to ethical
                guidelines
                on the use of AI </i></span>
    </p>
    
        <div style="height:380px; width:850px;">

            <iframe src="https://anniek-vqa.hf.space" frameborder="0" width="850" height="450"></iframe>

            <!-- <a href="https://huggingface.co/spaces/johngoad/Image-Caption" target="_blank" rel="noreferrer noopener"></a> -->
        </div>
    </div>
</div>